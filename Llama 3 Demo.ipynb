{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"0etRtS83RcWS"},"source":"# SingleStore and Llama 3 RAG Quickstart"},{"attachments":{},"cell_type":"markdown","metadata":{"id":"r1IzNLho-NqV"},"source":"This notebook provides an example of how to use SingleStore as a vector database in conjunction with Llama 3. We'll be using Replicate to host an instance of Llama 3 ov"},{"cell_type":"code","execution_count":133,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T16:23:26.745533Z","iopub.status.busy":"2024-04-30T16:23:26.745247Z","iopub.status.idle":"2024-04-30T16:23:29.724848Z","shell.execute_reply":"2024-04-30T16:23:29.724195Z","shell.execute_reply.started":"2024-04-30T16:23:26.745517Z"},"language":"python","trusted":true},"outputs":[],"source":"!pip install -q -U langchain singlestoredb langchain-openai --quiet"},{"cell_type":"code","execution_count":110,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T16:15:34.889051Z","iopub.status.busy":"2024-04-30T16:15:34.888805Z","iopub.status.idle":"2024-04-30T16:15:36.873714Z","shell.execute_reply":"2024-04-30T16:15:36.873113Z","shell.execute_reply.started":"2024-04-30T16:15:34.889035Z"},"language":"python","trusted":true},"outputs":[],"source":"!pip install replicate --quiet"},{"cell_type":"code","execution_count":125,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T16:20:57.102796Z","iopub.status.busy":"2024-04-30T16:20:57.102518Z","iopub.status.idle":"2024-04-30T16:21:15.655746Z","shell.execute_reply":"2024-04-30T16:21:15.655228Z","shell.execute_reply.started":"2024-04-30T16:20:57.102779Z"},"language":"python","trusted":true},"outputs":[{"name":"stdin","output_type":"stream","text":" ········\n"}],"source":"from getpass import getpass\n\nimport os\n\nREPLICATE_API_TOKEN = getpass()\n\nos.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN"},{"cell_type":"code","execution_count":138,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T16:25:44.319879Z","iopub.status.busy":"2024-04-30T16:25:44.319607Z","iopub.status.idle":"2024-04-30T16:25:45.720634Z","shell.execute_reply":"2024-04-30T16:25:45.720135Z","shell.execute_reply.started":"2024-04-30T16:25:44.319863Z"},"language":"python","trusted":true},"outputs":[{"name":"stdin","output_type":"stream","text":" ········\n"}],"source":"OPENAI_API_KEY = getpass()\n\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"},{"cell_type":"code","execution_count":126,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T16:21:22.269448Z","iopub.status.busy":"2024-04-30T16:21:22.269189Z","iopub.status.idle":"2024-04-30T16:21:22.272649Z","shell.execute_reply":"2024-04-30T16:21:22.272009Z","shell.execute_reply.started":"2024-04-30T16:21:22.269430Z"},"language":"python","trusted":true},"outputs":[],"source":"from langchain.chains import LLMChain\nfrom langchain_community.llms import Replicate\nfrom langchain_core.prompts import PromptTemplate"},{"attachments":{},"cell_type":"markdown","metadata":{"id":"m01XDoo4UQvN"},"source":"## Initialize Llama 3 in Replicate"},{"cell_type":"code","execution_count":131,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T16:23:00.001757Z","iopub.status.busy":"2024-04-30T16:23:00.001504Z","iopub.status.idle":"2024-04-30T16:23:08.353593Z","shell.execute_reply":"2024-04-30T16:23:08.353034Z","shell.execute_reply.started":"2024-04-30T16:23:00.001741Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"'SingleStoreDB is a distributed relational database that is designed to handle large amounts of data and scale horizontally. It is optimized for real-time analytics and machine learning workloads.\\n\\nSingleStoreDB is built from the ground up to be a cloud-native database. It is designed to take advantage of cloud computing, including scalability, high availability, and cost-effectiveness.\\n\\nSome of the key features of SingleStoreDB include:\\n\\n* Scalability: SingleStoreDB can scale horizontally to handle large amounts of data and increasing workloads.\\n* High availability: SingleStoreDB is designed to provide high availability, ensuring that your database is always available and accessible.\\n*'"},"execution_count":131,"metadata":{},"output_type":"execute_result"}],"source":"llm = Replicate(\n    model=\"meta/meta-llama-3-8b-instruct\",\n    model_kwargs={\"temperature\": 0.75, \"max_length\": 500, \"top_p\": 1},\n)\nprompt = \"\"\"\nUser: What is SingleStoreDB?\nAssistant:\n\"\"\"\nllm(prompt)"},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-04-26T08:44:11.362703Z","iopub.status.busy":"2024-04-26T08:44:11.362215Z","iopub.status.idle":"2024-04-26T08:44:11.364950Z","shell.execute_reply":"2024-04-26T08:44:11.364515Z","shell.execute_reply.started":"2024-04-26T08:44:11.362679Z"},"language":"python"},"source":"## RAG over audio files using SingleStoreDB\n\nNow we will embed the text descriptions of the audio file(s). This allows us to search and retrieve relevant files for RAG later."},{"cell_type":"code","execution_count":164,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T16:31:34.107933Z","iopub.status.busy":"2024-04-30T16:31:34.107351Z","iopub.status.idle":"2024-04-30T16:31:34.432853Z","shell.execute_reply":"2024-04-30T16:31:34.432358Z","shell.execute_reply.started":"2024-04-30T16:31:34.107910Z"},"language":"python","trusted":true},"outputs":[],"source":"from langchain.vectorstores import SingleStoreDB\nimport os\n\nfrom langchain_openai import OpenAIEmbeddings\n\nos.environ[\"SINGLESTOREDB_URL\"] = f'{connection_user}:{connection_password}@{connection_host}:{connection_port}/{connection_default_database}'"},{"cell_type":"code","execution_count":223,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T16:47:35.474206Z","iopub.status.busy":"2024-04-30T16:47:35.473942Z","iopub.status.idle":"2024-04-30T16:47:42.860963Z","shell.execute_reply":"2024-04-30T16:47:42.860466Z","shell.execute_reply.started":"2024-04-30T16:47:35.474190Z"},"language":"python","trusted":true},"outputs":[],"source":"from langchain.document_loaders import WebBaseLoader\n\nloader = WebBaseLoader(\"https://aws.amazon.com/blogs/aws/metas-llama-3-models-are-now-available-in-amazon-bedrock/\")\ndata = loader.load()"},{"cell_type":"code","execution_count":224,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T16:47:43.868724Z","iopub.status.busy":"2024-04-30T16:47:43.868477Z","iopub.status.idle":"2024-04-30T16:47:43.872090Z","shell.execute_reply":"2024-04-30T16:47:43.871572Z","shell.execute_reply.started":"2024-04-30T16:47:43.868710Z"},"language":"python","trusted":true},"outputs":[],"source":"from langchain.text_splitter import RecursiveCharacterTextSplitter\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\nall_splits = text_splitter.split_documents(data)"},{"cell_type":"code","execution_count":225,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T16:47:45.382362Z","iopub.status.busy":"2024-04-30T16:47:45.382119Z","iopub.status.idle":"2024-04-30T16:47:48.153998Z","shell.execute_reply":"2024-04-30T16:47:48.153403Z","shell.execute_reply.started":"2024-04-30T16:47:45.382348Z"},"language":"python","trusted":true},"outputs":[],"source":"vectorstore=SingleStoreDB.from_documents(documents=all_splits, table_name=\"test6\", embedding=OpenAIEmbeddings())"},{"cell_type":"code","execution_count":227,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T16:48:44.854397Z","iopub.status.busy":"2024-04-30T16:48:44.854136Z","iopub.status.idle":"2024-04-30T16:48:46.955494Z","shell.execute_reply":"2024-04-30T16:48:46.954897Z","shell.execute_reply.started":"2024-04-30T16:48:44.854376Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"{'query': 'How do you use Llama 3 models in the AWS console?',\n 'result': 'To use Llama 3 models in the AWS console, you can follow these steps:\\n\\n1. Log in to the AWS Management Console.\\n2. Navigate to the Amazon SageMaker console.\\n3. Click on the \"Models\" tab.\\n4. Click on the Llama 3 model you want to use.\\n5. In the \"Model details\" page, scroll down to the \"Use in a SageMaker notebook\" section.\\n6. Click on the \"Use\" button.\\n7. Review the following steps from the previous response.\\n\\nYou can also use the Llama 3 model to generate a new Llama 3 model to'}"},"execution_count":227,"metadata":{},"output_type":"execute_result"}],"source":"from langchain.chains import RetrievalQA\n\nqa_chain = RetrievalQA.from_chain_type(llm,retriever=vectorstore.as_retriever())\nqa_chain({\"query\": \"How do you use Llama 3 models in the AWS console?\"})"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"6efce35a-2db5-4ae3-bc0b-c3d5810a45f4","defaultDatabase":"llama3_demo"}},"nbformat":4,"nbformat_minor":4}