{"cells":[{"cell_type":"code","execution_count":null,"id":"db397f6b-15cf-451b-b52c-ba82e6d08764","metadata":{"tags":[],"trusted":true},"outputs":[],"source":"OPENAI_API_KEY = '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'\nOPENAI_ORG = 'org-hCeWR2E9cHDb3qoybaEBHfU6'"},{"cell_type":"markdown","id":"d977a96a-791b-4e4f-9690-51b4d79112eb","metadata":{},"source":"# Using GPT for Product Recommendation Engines\n\nToday we will be using SingleStore Kaiâ„¢ for MongoDB, along with OpenAI, to put together a simple product recommendation engine in Python."},{"cell_type":"markdown","id":"4c6998dc-9a1c-452d-8bba-4b631ec189da","metadata":{},"source":"## Import Dataset\n\nFirst, we'll import a dataset into our database. Let's use [Open Library's Works](https://openlibrary.org/data/ol_dump_works_latest.txt.gzhttps://openlibrary.org/data/ol_dump_works_latest.txt.gz) dataset.\n\nFor the sake of brevity for the webinar, we've downloaded the extremely large dataset linked above and restricted it to "},{"cell_type":"markdown","id":"5b35a875-8245-462f-b02e-e0a9f97c9ac4","metadata":{},"source":"### Download Dataset"},{"cell_type":"code","execution_count":null,"id":"8485cfce-9287-4513-a30b-bae0d60df011","metadata":{"tags":[],"trusted":true},"outputs":[],"source":"import requests\n\ndataset_url = 'https://raw.githubusercontent.com/singlestore-labs/webinar-code-examples/main/kai-product-rec/books_scifi.txt'\n\ndef download_file(dataset_url):\n    local_filename = dataset_url.split('/')[-1]\n    with requests.get(dataset_url, stream=True) as r:\n        r.raise_for_status()\n        with open(local_filename, 'wb') as f:\n            for chunk in r.iter_content(chunk_size=8192): \n                # If you have chunk encoded response uncomment if\n                # and set chunk_size parameter to None.\n                #if chunk: \n                f.write(chunk)\n    return local_filename\n\nlocal_dataset = download_file(dataset_url)"},{"cell_type":"markdown","id":"08df354e-a408-4b83-955c-40eb75760d09","metadata":{},"source":"### Read text file into variable"},{"cell_type":"code","execution_count":null,"id":"a9583590-f3dc-4ec1-b325-4068177a9e02","metadata":{"tags":[],"trusted":true},"outputs":[],"source":"file = open(local_dataset)\ndata = file.readlines()\nfile.close()"},{"cell_type":"code","execution_count":null,"id":"2594abfa-2268-4330-8b33-3fe1e3485c70","metadata":{"tags":[],"trusted":true},"outputs":[],"source":"cost_per_1k = 0.004\ndollar_limit = 20.00\nbudget_tokens = (dollar_limit / cost_per_1k) * 1000\ntoken_usage = 0\n\ndef budget_status(token_usage):\n    if budget_tokens \u003e token_usage:\n        return 'ok'\n    else:\n        return 'spent'"},{"cell_type":"markdown","id":"48186a20-4e4a-44cd-8105-b82a9976cc1f","metadata":{"tags":[]},"source":"### Create SQL Table\n\nHere we are creating the table to store our books in. We will have "},{"cell_type":"code","execution_count":null,"id":"5908bfd7-e9bb-48f1-a1f0-a2b9d56896db","metadata":{"tags":[],"trusted":true},"outputs":[],"source":"%%sql\nCREATE TABLE IF NOT EXISTS products (\n  _id INT AUTO_INCREMENT PRIMARY KEY,\n  title VARCHAR(255) NOT NULL,\n  embedding BLOB NOT NULL\n);"},{"cell_type":"markdown","id":"a49f62e2-0f55-4eb2-bf9f-aa236e272eff","metadata":{},"source":"## Helpers\n\n### Track Token Usage\n\nYou should be mindful to track your token usage to ensure you don't blow your budget on any particular project. This is rudimentary, but should do the trick for our simple project today.\n\n**Note:** Pricing changes often, check [here](https://openai.com/pricing) and adjust the pricing as necessary.\n\nThe function below will return 'ok' if our budget hasn't been spent yet, if it has, then it will return 'spent'."},{"cell_type":"markdown","id":"2da984d0-6899-4150-b39a-1c246e386ece","metadata":{},"source":"### Create Embeddings and Load into S2\n\nNow we need to loop through the dataset to create the embeddings using the OpenAI API. \n\nThis process will track token usage and bail if we've spent our budget."},{"cell_type":"code","execution_count":null,"id":"3e90767b-12c9-4511-bd66-2831691b9a83","metadata":{"tags":[],"trusted":true},"outputs":[],"source":"!pip install openai\n\nimport openai\nimport ast\nfrom sqlalchemy import *\n\nopenai.organization = OPENAI_ORG\nopenai.api_key = OPENAI_API_KEY\n\nconn = create_engine(connection_url)\n\nmodel_id = 'text-embedding-ada-002'\n\nds_with_embeddings = []\ntotal_items = len(data)\n\ndef request_embedding(text, token_usage):\n    \n    budget = budget_status(token_usage)\n    \n    if budget == 'ok':\n        #print('Budget status: OK\\nTokens: {}/{}'.format(token_usage,budget_tokens))\n        try:\n            if OPENAI_API_KEY:\n                response = openai.Embedding.create(input=text,model=model_id)\n                embedding = response['data'][0]['embedding']\n                tokens = response['usage']['total_tokens']\n                status = 'success'\n                #print(embedding)\n                return embedding,tokens,status\n            else:\n                print('You need to set your OpenAI API Key to the variable OPENAI_API_KEY')\n        except Exception as e:\n            print(e)\n            embedding = ''\n            tokens = 0\n            status = 'failed'\n            return embedding,tokens,status\n    else:\n        print('Budget Spent: {}/{}'.format(token_usage,budget_tokens))\n        embedding = ''\n        tokens = 0\n        status = 'budget_spent'\n        return embedding,tokens,status\n\ndef write_to_db(data):\n    keys = [\"title\", \"embedding\" ];\n    query = \"INSERT INTO products (title, embedding) VALUES (%s, JSON_ARRAY_PACK_F32(%s))\"\n    \n    try:\n        with conn:\n            conn.execute(query, (data[keys[0]].replace(\"'\",\"\"), str(data[keys[1]])))\n            print(\"Wrote item\")\n    except Exception as e:\n        print(e)\n    \n\nloop_counter = 0\nprint('Requesting embeddings. I will update you every 1000 embeddings.')\nfor b in data:\n    try:\n        embedding,tokens,status = request_embedding(b, token_usage)\n        if status != 'failed' and status != 'budget_spent':\n            book = ast.literal_eval(b)\n            book['embedding'] = embedding\n            write_to_db(book)\n            token_usage += tokens\n            #print('Completed {}/{}'.format(len(ds_with_embeddings),total_items))\n            loop_counter += 1\n            if loop_counter == 1000:\n                print('Completed {}/{}'.format(len(ds_with_embeddings),total_items))\n                print('Token usage: {}/{}'.format(token_usage,budget_tokens))\n                loop_counter = 0\n        elif status == 'budget_spent':\n            print('Getting embedding failed because the budget is spent.')\n        else:\n            print('Getting embedding for this book failed:\\n{}'.format(b))\n    except Exception as e:\n        print(e)\n        \nconn.close()\n"},{"cell_type":"code","execution_count":null,"id":"b23b6746-8a17-4441-abd4-9ae6d7d8b648","metadata":{},"outputs":[],"source":"query = 'The Martian'\n\n\n\nsql_query = 'SELECT title FROM products WHERE EUCLIDEAN_DISTANCE(vector, JSON_ARRAY_PACK('query')) ;\n\nSELECT EUCLIDEAN_DISTANCE(vector, JSON_ARRAY_PACK('[5.9,3,5.1,1.8]')) AS euclidean_distance, title\nFROM products\nORDER BY euclidean_distance\nLIMIT 5;\n\n"},{"cell_type":"code","execution_count":null,"id":"1906aa2c-8929-4e70-b64b-6843359323ec","metadata":{},"outputs":[],"source":""}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"singlestore_connection":{"connectionID":"00336d64-e4db-4635-aa2b-4ab9f330727a","defaultDatabase":"kai_product_rec"},"singlestore_row_limit":300},"nbformat":4,"nbformat_minor":5}